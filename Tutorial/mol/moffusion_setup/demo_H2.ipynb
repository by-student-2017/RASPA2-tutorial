{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo for Hydrogen Uptake Conditinoing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Designate GPU to use\n",
    "import os\n",
    "gpu_ids = 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_ids}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from IPython.display import Image as ipy_image\n",
    "from IPython.display import display\n",
    "from termcolor import colored, cprint\n",
    "\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True\n",
    "import torchvision.utils as vutils\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import OrderedDict\n",
    "from models.base_model import create_model\n",
    "from utils.util_3d import render_sdf, render_mesh, sdf_to_mesh, save_mesh_as_gif\n",
    "from utils.build_materials import build_materials\n",
    "from utils.pormake_serialize import serialize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "\n",
    "from visualize.visualizer import MOFVisualizer, animate, resize_gif, make_concat_gif\n",
    "from PIL import Image, ImageSequence\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] MOFFUSION-H2-Option initialized.\n"
     ]
    }
   ],
   "source": [
    "# options for the model. please check `utils/demo_util.py` for more details\n",
    "from utils.demo_util import MOFFUSIONH2Opt\n",
    "\n",
    "seed = 1\n",
    "opt = MOFFUSIONH2Opt(gpu_ids=gpu_ids, seed=seed)\n",
    "device = opt.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[*] VQVAE: weight successfully load from: ./saved_ckpt/vqvae.pth\u001b[0m\n",
      "\u001b[34m[*] weight successfully load from: saved_ckpt/moffusion_H2.pth\u001b[0m\n",
      "\u001b[34m[*] setting ddim_steps=200\u001b[0m\n",
      "\u001b[34m[*] Model has been created: MOFFUSION-H2-Model\u001b[0m\n",
      "\u001b[36m[*] \"MOFFUSION-H2-Model\" loaded.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Initialize MOFFUSION-H2 model\n",
    "ckpt_path = 'saved_ckpt/moffusion_H2.pth'\n",
    "\n",
    "opt.init_model_args(ckpt_path=ckpt_path)\n",
    "MOFFUSION = create_model(opt)\n",
    "cprint(f'[*] \"{MOFFUSION.name()}\" loaded.', 'cyan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[*] weight successfully load from: ./saved_ckpt/mof_constructor_topo.pth\u001b[0m\n",
      "\u001b[34m[*] Model has been created: MOF-Constructor_Topo-Model\u001b[0m\n",
      "\u001b[36m[*] \"mof_constructor_topo\" initialized.\u001b[0m\n",
      "\u001b[34m[*] weight successfully load from: ./saved_ckpt/mof_constructor_BB.pth\u001b[0m\n",
      "\u001b[34m[*] Model has been created: MOF-Constructor_BB-Model\u001b[0m\n",
      "\u001b[36m[*] \"mof_constructor_BB\" initialized.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# initialize Cascaded MOF Constructor\n",
    "# A model for topology prediction\n",
    "opt.model = opt.res_topo_model\n",
    "opt.ckpt = opt.res_topo_ckpt\n",
    "res_topo_model = create_model(opt)\n",
    "cprint(f'[*] \"{opt.model}\" initialized.', 'cyan')\n",
    "\n",
    "# A model for building blocks prediction\n",
    "opt.model = opt.res_BB_model\n",
    "opt.ckpt = opt.res_BB_ckpt\n",
    "res_BB_model = create_model(opt)\n",
    "cprint(f'[*] \"{opt.model}\" initialized.', 'cyan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mCaution! A folder with the same name might cause undesired situations. Please remove the old folder.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Designate target H2 WC, number of generation attempts, and repository to save\n",
    "\n",
    "# Caution! WC values are normlized. All values are divided by 100\n",
    "# For example, target value of 0.3 -> 30 g/L\n",
    "\n",
    "# If ngen is too large, it is recommended to split it into several batches \n",
    "\n",
    "target=0.30\n",
    "ngen=20\n",
    "save_dir='./samples/Demo_H2'\n",
    "save_dir_path = Path(save_dir)\n",
    "if save_dir_path.exists():\n",
    "    cprint('Caution! A folder with the same name might cause undesired situations. Please remove the old folder.', 'cyan')\n",
    "save_dir_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape for DDIM sampling is (20, 3, 8, 8, 8), eta 0.0\n",
      "Running DDIM Sampling with 200 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampler: 100%|███████████████████████████████████████████████████████████████████| 200/200 [00:21<00:00,  9.36it/s]\n",
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1+cu118\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m[*] SDF Generated\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m[*] SDF Generated\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Generation Begins!\n",
    "MOFFUSION.cond(ngen=ngen, target=target)\n",
    "gen_df = MOFFUSION.gen_df\n",
    "\n",
    "# Save generated SDFs into repository\n",
    "for i in range(len(gen_df)):\n",
    "    np.save(f'{save_dir}/{i}.npy', gen_df[i].detach().cpu())\n",
    "\n",
    "cprint(f'[*] SDF Generated', 'cyan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m[*] Topology Predicted\u001b[0m\n",
      "\u001b[36m[*] Building Blocks Predicted\u001b[0m\n",
      "\u001b[36m[*] Result saved in ./samples/Demo_H2/MOF_Constructor_output.txt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Obtain MOFs using MOF Constructor\n",
    "\n",
    "# initialize Enocders for topology/node/edge\n",
    "topo_encoder = opt.encoders['topo'] \n",
    "node_encoder = opt.encoders['node'] \n",
    "edge_encoder = opt.encoders['edge'] \n",
    "\n",
    "\n",
    "# 1. Cascaded MOF Constructor (Topology)\n",
    "topo_pred = res_topo_model.predict(gen_df)\n",
    "cprint(f'[*] Topology Predicted', 'cyan')\n",
    "\n",
    "\n",
    "# 2. Cascaded MOF Constructor (Building Blocks)\n",
    "mof_pred = res_BB_model.predict(gen_df, topo_pred)\n",
    "cprint(f'[*] Building Blocks Predicted', 'cyan')\n",
    "\n",
    "\n",
    "# Save result as text file\n",
    "with open (f'{save_dir}/MOF_Constructor_output.txt', 'a') as f:\n",
    "    for mof in mof_pred:\n",
    "        topos = topo_encoder.inverse_transform(mof[0].tolist())\n",
    "        nodes_1 = node_encoder.inverse_transform(mof[1].tolist())\n",
    "        nodes_2 = node_encoder.inverse_transform(mof[2].tolist())       \n",
    "        edges = edge_encoder.inverse_transform(mof[3].tolist())    \n",
    "\n",
    "        if nodes_2 == 'N0':\n",
    "            f.write(topos[0]+'+'+nodes_1[0]+'+'+edges[0]+'\\n')\n",
    "        else:\n",
    "            f.write(topos[0]+'+'+nodes_1[0]+'+'+nodes_2[0]+'+'+edges[0]+'\\n') \n",
    "\n",
    "cprint(f'[*] Result saved in {save_dir}/MOF_Constructor_output.txt', 'cyan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start generation.\n",
      "fns+N583+E11 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2025-07-25 16:41:32,204:jax._src.xla_bridge:969: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n",
      "WARNING:jax._src.xla_bridge:An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success (small).\n",
      "nom+N448+N700+E92 Success (small).\n",
      "nom+N447+N693+E51 Success (small).\n",
      "wjz+N671+E181 Success (large).\n",
      "eta+N383+E116 Success (small).\n",
      "vmk+N101+E150 Success (small).\n",
      "wix+N117+E208 Success (small).\n",
      "fnr+N482+E16 Success (small).\n",
      "can+N393+E158 Success (small).\n",
      "crr+N489+E228 Success (small).\n",
      "sth+N482+E202 Success (small).\n",
      "sxd+N356+E33 Success (small).\n",
      "bor+N136+N203+E56 Success (large).\n",
      "fns+N572+E123 Success (small).\n",
      "fna+N172+E177 Success (small).\n",
      "sxc+N300+E129 yfh+N391+E127 Success (small).\n",
      "wjp+N482+E202 Success (small).\n",
      "ukf+N164+E134 Success (small).\n",
      "fob+N391+E162 Success (small).\n",
      "fns+N583+E11 Success (small).\n",
      "nom+N448+N700+E92 Success (small).\n",
      "nom+N447+N693+E51 Success (small).\n",
      "wjz+N671+E181 Success (large).\n",
      "eta+N383+E116 Success (small).\n",
      "vmk+N101+E150 Success (small).\n",
      "wix+N117+E208 Success (small).\n",
      "fnr+N482+E186 Success (small).\n",
      "can+N393+E158 Success (small).\n",
      "crr+N489+E228 Success (small).\n",
      "sth+N482+E202 Success (small).\n",
      "sxd+N272+E33 bor+N136+N203+E56 Success (large).\n",
      "fns+N572+E123 Success (small).\n",
      "fna+N172+E177 Success (small).\n",
      "sxc+N300+E129 yfh+N391+E127 Success (small).\n",
      "wjp+N482+E202 Success (small).\n",
      "ukf+N164+E134 Success (small).\n",
      "fob+N391+E162 Success (small).\n",
      "End generation.\n",
      "\u001b[36m[*] MOFs Generated in ./samples/Demo_H2/mof_success\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Generate MOF structures using PORMAKE\n",
    "\n",
    "# For convenience, generated structures are divided as follows:\n",
    "# mof_gen_success : generated MOFs with cell length smaller than 60 Å\n",
    "# mof_gen_large : generated MOFs with cell length larger than 60 Å\n",
    "\n",
    "# Prepare repositories to store\n",
    "mof_gen_success = f'{save_dir}/mof_success'\n",
    "mof_gen_large = f'{save_dir}/mof_large_cell'\n",
    "\n",
    "success_dir = Path(mof_gen_success)\n",
    "success_dir.mkdir(exist_ok=True)\n",
    "\n",
    "fail_dir = Path(mof_gen_large)\n",
    "fail_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Start generation\n",
    "try:\n",
    "    build_materials(candidate_file = f'{save_dir}/MOF_Constructor_output.txt', save_dir = mof_gen_success, large_dir = mof_gen_large)\n",
    "except FileNotFoundError:\n",
    "    pass\n",
    "cprint(f'[*] MOFs Generated in {save_dir}/mof_success', 'cyan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import animation\n",
    "from matplotlib.animation import PillowWriter\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "\n",
    "def animate(func, savefile=None, fps=30, **kwargs):\n",
    "    def wrapper(*args, **kwargs_inner):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "        anim = animation.FuncAnimation(\n",
    "            fig,\n",
    "            partial(func, ax=ax, fig=fig, **kwargs),\n",
    "            frames=range(0, 360, 3),\n",
    "            interval=50,\n",
    "            blit=False,\n",
    "        )\n",
    "\n",
    "        if savefile:\n",
    "            writer = PillowWriter(fps=fps)\n",
    "            anim.save(savefile, writer=writer, dpi=100)\n",
    "\n",
    "        plt.close()\n",
    "        return anim\n",
    "\n",
    "    return wrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c9bb85e944c303a90ba1b7f3901817f7bc3ecb5f736863b2299a6fa67a7b3c89"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
